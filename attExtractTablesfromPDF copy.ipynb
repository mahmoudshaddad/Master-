{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtractTablesfromPDF\n",
    "\n",
    "In this notebook, run the Table Transformer - which is actually a [DETR](https://arxiv.org/abs/2005.12872) model - by Microsoft Research to perform table detection and on documents (Pdfs and Images).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\engin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\engin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.GIT 'C:\\Users\\engin\\AppData\\Local\\Temp\\pip-req-build-hyyq28ew' did not run successfully.\n",
      "  │ exit code: 128\n",
      "  ╰─> [2 lines of output]\n",
      "      remote: Repository not found.\n",
      "      fatal: repository 'https://github.com/huggingface/transformers.GIT/' not found\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.GIT 'C:\\Users\\engin\\AppData\\Local\\Temp\\pip-req-build-hyyq28ew' did not run successfully.\n",
      "│ exit code: 128\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q git+https://github.com/huggingface/transformers.GIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\engin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\engin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\engin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\engin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\engin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.7.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\engin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\engin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\engin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\engin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy<2,>=1.20 in c:\\users\\engin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\engin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\engin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\engin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\engin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\engin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\engin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\engin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\engin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\engin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdf2image"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\engin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\engin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\engin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\engin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\engin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdf2image) (9.5.0)\n",
      "Using cached pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pdf2image\n",
      "Successfully installed pdf2image-1.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -q timm\n",
    "!pip install matplotlib\n",
    "!pip install pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall tokenizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tokenizers==0.14.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table detection\n",
    "\n",
    "Table detection is the task of detect tables in document images, like PDFs.\n",
    "\n",
    "Let's load a PDF and see how our model does.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the pdf_Pages to images:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m pdf_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m00Master\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDemo\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata acc\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDIN EN 206.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     33\u001b[0m output_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m00Master\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDemo\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata acc\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtesttest\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 34\u001b[0m imgs \u001b[38;5;241m=\u001b[39m extract_images_from_pdf(pdf_path, output_folder)\n",
      "Cell \u001b[1;32mIn[8], line 22\u001b[0m, in \u001b[0;36mextract_images_from_pdf\u001b[1;34m(pdf_path, output_folder)\u001b[0m\n\u001b[0;32m     19\u001b[0m pdf_filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(pdf_path)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Convert PDF pages to images\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m images \u001b[38;5;241m=\u001b[39m convert_from_path(pdf_path)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Save each page as an image\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, image \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(images):\n",
      "File \u001b[1;32mc:\\Users\\engin\\anaconda3\\Lib\\site-packages\\pdf2image\\pdf2image.py:250\u001b[0m, in \u001b[0;36mconvert_from_path\u001b[1;34m(pdf_path, dpi, output_folder, first_page, last_page, fmt, jpegopt, thread_count, userpw, ownerpw, use_cropbox, strict, transparent, single_file, output_file, poppler_path, grayscale, size, paths_only, use_pdftocairo, timeout, hide_annotations)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m uid, proc \u001b[38;5;129;01min\u001b[39;00m processes:\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 250\u001b[0m         data, err \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mcommunicate(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired:\n\u001b[0;32m    252\u001b[0m         proc\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[1;32mc:\\Users\\engin\\anaconda3\\Lib\\subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[1;34m(self, input, timeout)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1209\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_communicate(\u001b[38;5;28minput\u001b[39m, endtime, timeout)\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\engin\\anaconda3\\Lib\\subprocess.py:1626\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[1;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[0;32m   1622\u001b[0m \u001b[38;5;66;03m# Wait for the reader threads, or time out.  If we time out, the\u001b[39;00m\n\u001b[0;32m   1623\u001b[0m \u001b[38;5;66;03m# threads remain reading and the fds left open in case the user\u001b[39;00m\n\u001b[0;32m   1624\u001b[0m \u001b[38;5;66;03m# calls communicate again.\u001b[39;00m\n\u001b[0;32m   1625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1626\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout_thread\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_remaining_time(endtime))\n\u001b[0;32m   1627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m   1628\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TimeoutExpired(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, orig_timeout)\n",
      "File \u001b[1;32mc:\\Users\\engin\\anaconda3\\Lib\\threading.py:1112\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock()\n\u001b[0;32m   1113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1114\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\engin\\anaconda3\\Lib\\threading.py:1132\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lock\u001b[38;5;241m.\u001b[39macquire(block, timeout):\n\u001b[0;32m   1133\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 35.3 s (started: 2023-12-31 09:49:08 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# from pdf2image import convert_from_path\n",
    "# import os\n",
    "\n",
    "# def extract_images_from_pdf(pdf_path, output_folder):\n",
    "#     \"\"\"\n",
    "#     Extracts all pages from a PDF file and saves them as images\n",
    "#     in the specified output folder.\n",
    "\n",
    "#     Args:\n",
    "#     pdf_path (str): The path to the PDF file.\n",
    "#     output_folder (str): The folder where the extracted images will be saved.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Create the output folder if it does not exist\n",
    "#     if not os.path.exists(output_folder):\n",
    "#         os.makedirs(output_folder)\n",
    "\n",
    "#     # Extract the base filename from the PDF path\n",
    "#     pdf_filename = os.path.basename(pdf_path).replace(\".pdf\", \"\")\n",
    "\n",
    "#     # Convert PDF pages to images\n",
    "#     images = convert_from_path(pdf_path)\n",
    "\n",
    "#     # Save each page as an image\n",
    "#     for i, image in enumerate(images):\n",
    "#         image.save(os.path.join(output_folder, f\"{pdf_filename}_page_{i}.png\"), \"PNG\")\n",
    "\n",
    "#     return images\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# pdf_path = r\"C:\\A\\00Master\\Demo\\data acc\\DIN EN 206.pdf\"\n",
    "# output_folder = r\"C:\\A\\00Master\\Demo\\data acc\\testtest\"\n",
    "# imgs = extract_images_from_pdf(pdf_path, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extractor\n",
    "\n",
    "- Appling the regular image preprocessing using `DetrImageProcessor`. The feature extractor will resize the image (minimum size = 800, max size = 1333), and normalize it across the channels using the ImageNet mean and standard deviation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autotime\n",
    "from transformers import DetrImageProcessor,TableTransformerForObjectDetection\n",
    "from transformers import TableTransformerForObjectDetection\n",
    "\n",
    "\n",
    "\n",
    "# feature_extractor = DetrFeatureExtractor()    => # it will be deleted in the future \n",
    "\n",
    "feature_extractor = DetrImageProcessor()\n",
    "encoding = feature_extractor(imgs, return_tensors=\"pt\")\n",
    "# encoding = feature_extractor(image, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "model = TableTransformerForObjectDetection.from_pretrained(\"microsoft/table-transformer-detection\")\n",
    "\n",
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "  outputs = model(**encoding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2023-12-31 09:50:27 +01:00)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def detect_and_crop_tables(images, model, feature_extractor, output_folder, pdf_filename, padding=0):\n",
    "    from PIL import Image\n",
    "    import torch\n",
    "\n",
    "    def crop_tables(image, page_num):\n",
    "        encoding = feature_extractor(image, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encoding)\n",
    "\n",
    "        width, height = image.size\n",
    "        target_sizes = [(height, width)]\n",
    "        results = feature_extractor.post_process_object_detection(outputs, threshold=0.9, target_sizes=target_sizes)[0]\n",
    "\n",
    "        high_score_tables = [(score, label, box) for score, label, box in\n",
    "                             zip(results['scores'].tolist(),\n",
    "                                  results['labels'].tolist(), \n",
    "                                  results['boxes'].tolist())\n",
    "                             if score > 0.9]\n",
    "\n",
    "        if high_score_tables:\n",
    "            for idx, (_, _, (xmin, ymin, xmax, ymax)) in enumerate(high_score_tables):\n",
    "                xmin -= padding\n",
    "                ymin -= padding\n",
    "                xmax += padding\n",
    "                ymax += padding\n",
    "                table_img = image.crop((xmin, ymin, xmax, ymax))\n",
    "                table_img.save(os.path.join(output_folder, f\"{pdf_filename}_page_{page_num}_table_{idx}.png\"), \"PNG\")\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        crop_tables(image, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/table-transformer-detection were not used when initializing TableTransformerForObjectDetection: ['model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scores': tensor([0.9997]), 'labels': tensor([0]), 'boxes': tensor([[ 118.8181, 1222.5436, 1445.8184, 2016.4642]])}\n",
      "<class 'dict'>\n",
      "time: 1.5 s (started: 2023-12-31 10:12:38 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# %reload_ext autotime\n",
    "from PIL import Image\n",
    "\n",
    "file_path = r\"C:\\A\\00Master\\Demo\\data acc\\testtest\\DIN EN 206_page_87.png\"\n",
    "image = Image.open(file_path).convert(\"RGB\")\n",
    "width, height = image.size\n",
    "image.resize((int(width*0.5), int(height*0.5)))\n",
    "\n",
    "from transformers import DetrImageProcessor,TableTransformerForObjectDetection\n",
    "from transformers import TableTransformerForObjectDetection\n",
    "\n",
    "\n",
    "\n",
    "# feature_extractor = DetrFeatureExtractor()    => # it will be deleted in the future \n",
    "\n",
    "feature_extractor = DetrImageProcessor()\n",
    "encoding = feature_extractor(image, return_tensors=\"pt\")\n",
    "# encoding = feature_extractor(image, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "model = TableTransformerForObjectDetection.from_pretrained(\"microsoft/table-transformer-detection\")\n",
    "\n",
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "  outputs = model(**encoding)\n",
    "\n",
    "\n",
    "# rescale bounding boxes\n",
    "width, height = image.size\n",
    "target_sizes = [(height, width)] * len(outputs.logits)  # Make sure to pass the correct number of target sizes\n",
    "\n",
    "results = feature_extractor.post_process_object_detection(outputs,\n",
    "                                                           threshold=0.9, \n",
    "                                                           target_sizes=target_sizes)[0]\n",
    "\n",
    "print(results)\n",
    "print(type(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/table-transformer-detection were not used when initializing TableTransformerForObjectDetection: ['model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/06/2023 08:33:34\n",
      "\n",
      "Printed copies are uncontrolled\n",
      "\n",
      "DIN EN 206:2021-06\n",
      "EN 206:2013+A2:2021 (D)\n",
      "\n",
      "ANMERKUNG Weitere Informationen enthält Anhang L, Zeile 20.\n",
      "\n",
      "(4) Für Leichtbeton, der mit ungesättigter Gesteinskörnung dosiert wird, muss die Dauer zwischen dem\n",
      "Erstmischen und dem Ende des letzten Mischvorgangs (z.B. erneutes Mischen in einem Fahrmischer) so\n",
      "verlängert werden, dass die Wasseraufnahme der Gesteinskörnung und das nachfolgende Entweichen der\n",
      "Luft aus der leichten Gesteinskörnung keine nachteilige Auswirkung auf die Eigenschaften des Festbetons\n",
      "haben.\n",
      "\n",
      "(5) Die Zusammensetzung des Frischbetons darf nach Verlassen des Mischers nicht verändert werden.\n",
      "\n",
      "9.9 Verfahren der Produktionskontrolle\n",
      "\n",
      "(1) Ausgangsstoffe, Ausstattung, Herstellverfahren und Beton müssen in Hinblick auf ihre Konformität mit\n",
      "den Festlegungen für den Beton und den Anforderungen dieser Norm überwacht werden. Die\n",
      "Produktionskontrolle muss so angelegt sein, dass wesentliche Änderungen, die die Eigenschaften\n",
      "beeinflussen, aufgedeckt und angemessene Gegenmaßnahmen eingeleitet werden.\n",
      "\n",
      "(2) Es ist ein Verfahren einzurichten, das die korrekte Lieferung, Lagerung und Verwendung der\n",
      "Ausgangsstoffe sicherstellt und die folgenden Merkmale aufweist:\n",
      "\n",
      "— Prüfung, ob das angelieferte Material mit der Bestellung übereinstimmt;\n",
      "— Prüfung, ob das Material am richtigen Ort abgeladen wird;\n",
      "— Verhinderung des Abladens von offensichtlich nichtkonformen Materialien;\n",
      "\n",
      "— Lagerung des Materials so, dass das Risiko von Verunreinigungen oder Beeinträchtigungen der Qualität\n",
      "minimiert wird;\n",
      "\n",
      "— Dokumentation der Lieferungen;\n",
      "\n",
      "— Prüfung aller Lieferungen in Zweifelsfällen, bei denen bestimmte Eigenschaften nicht mit der\n",
      "mafßgebenden Norm oder einer anderen Spezifikation übereinzustimmen scheinen;\n",
      "\n",
      "— Prüfung des Wassergehaltes der Gesteinskörnung.\n",
      "\n",
      "ANMERKUNG Um einen gleichmäßigen selbstverdichtenden Beton herzustellen, ist es notwendig, Ausgangsstoffe mit\n",
      "gleichmäßigen Eigenschaften zu verwenden. Es könnte erforderlich sein, diese Eigenschaften häufiger als beim üblichen\n",
      "Beton zu überprüfen.\n",
      "\n",
      "(3) Falls ein Hersteller die Gesteinskörnung selbst herstellt, ist er als Hersteller der Gesteinskörnung zu\n",
      "betrachten und muss die technischen Aspekte der maßgebenden Europäischen Norm für Gesteinskörnungen\n",
      "einhalten.\n",
      "\n",
      "(4) Die Kontrolle der Ausstattung muss sicherstellen, dass die Lager-, Wäge- und Messeinrichtungen, der\n",
      "Mischer und die Steuerungsgeräte (z.B. zum Messen des Wassergehaltes der Gesteinskörnung) in gutem\n",
      "Betriebszustand sind und dass sie den Anforderungen dieser Norm entsprechen. Die Häufigkeit der\n",
      "Überprüfungen und die Prüfungen der Ausstattung (sofern verwendet) sind in Tabelle 28 angegeben.\n",
      "\n",
      "(5) Die Werksanlage, Ausstattung und Transporteinrichtungen müssen einem planmäßigen\n",
      "Wartungssystem unterliegen und in einem wirksamen Betriebszustand gehalten werden, damit\n",
      "\n",
      "Eigenschaften und Liefermenge des Betons nicht nachteilig beeinflusst werden.\n",
      "\n",
      "(6) Die Eigenschaften von Beton nach Eigenschaften müssen auf die nach Tabelle 29 festgelegten\n",
      "Anforderungen hin überwacht werden.\n",
      "\n",
      "66\n",
      "\n",
      "Technische Universität Darmstadt\n",
      "\n",
      "time: 3.55 s (started: 2023-12-31 10:42:06 +01:00)\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image, ImageDraw\n",
    "from transformers import DetrImageProcessor, TableTransformerForObjectDetection\n",
    "import torch\n",
    "\n",
    "# Set the path to the Tesseract executable\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Load the image\n",
    "file_path = r'C:\\A\\00Master\\Demo\\data acc\\testtest\\DIN EN 206_page_69.png'\n",
    "image = Image.open(file_path).convert(\"RGB\")\n",
    "\n",
    "# Detect tables\n",
    "feature_extractor = DetrImageProcessor()\n",
    "model = TableTransformerForObjectDetection.from_pretrained(\"microsoft/table-transformer-detection\")\n",
    "\n",
    "encoding = feature_extractor(image, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = model(**encoding)\n",
    "\n",
    "# Rescale bounding boxes\n",
    "width, height = image.size\n",
    "target_sizes = [(height, width)] * len(outputs.logits)\n",
    "results = feature_extractor.post_process_object_detection(outputs, threshold=0.9, target_sizes=target_sizes)[0]\n",
    "\n",
    "# Create a copy of the image to perform OCR\n",
    "image_for_ocr = image.copy()\n",
    "draw = ImageDraw.Draw(image_for_ocr)\n",
    "\n",
    "# Cover detected tables with white rectangles\n",
    "for box in results['boxes']:\n",
    "    draw.rectangle([(box[0], box[1]), (box[2], box[3])], fill=\"white\")\n",
    "\n",
    "# Perform OCR on the image with tables excluded\n",
    "text_without_tables = pytesseract.image_to_string(image_for_ocr, lang='deu')\n",
    "\n",
    "print(text_without_tables)\n",
    "def write_text_to_file(text, file_path):\n",
    "    \"\"\"\n",
    "    Writes given text to a .txt file at the specified file path.\n",
    "\n",
    "    :param text: The text to be written to the file.\n",
    "    :param file_path: The path (including filename) where the file should be saved.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(text)\n",
    "\n",
    "# Example usage\n",
    "\n",
    "output_file_path = 'outputSHaddadwithgermanwithoutonetable.txt'  # Specify your desired file path\n",
    "\n",
    "write_text_to_file(text_without_tables, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scores': tensor([0.9943, 0.9992]), 'labels': tensor([0, 0]), 'boxes': tensor([[ 383.1478,  696.4118, 1154.8029, 1158.4928],\n",
      "        [ 518.7551, 1757.9453, 1108.2152, 2017.1786]])}\n",
      "time: 16 ms (started: 2023-12-31 09:53:15 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# import pytesseract\n",
    "# from PIL import Image\n",
    "# import pandas as pd\n",
    "# from transformers import DetrImageProcessor, TableTransformerForObjectDetection\n",
    "# import torch\n",
    "# import json\n",
    "\n",
    "# # Configure PyTesseract\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'path_to_tesseract.exe'  # Update the path\n",
    "\n",
    "# # Load image\n",
    "# file_path = r\"your_image_path.png\"\n",
    "# image = Image.open(file_path).convert(\"RGB\")\n",
    "\n",
    "# # Initialize the feature extractor and model\n",
    "# feature_extractor = DetrImageProcessor()\n",
    "# model = TableTransformerForObjectDetection.from_pretrained(\"microsoft/table-transformer-detection\")\n",
    "\n",
    "# # Process image for table detection\n",
    "# encoding = feature_extractor(image, return_tensors=\"pt\")\n",
    "# with torch.no_grad():\n",
    "#     outputs = model(**encoding)\n",
    "\n",
    "# # Rescale bounding boxes\n",
    "# width, height = image.size\n",
    "# target_sizes = [(height, width)] * len(outputs.logits)\n",
    "# results = feature_extractor.post_process_object_detection(outputs, threshold=0.9, target_sizes=target_sizes)[0]\n",
    "\n",
    "# # Extract tables and texts\n",
    "# data_json = {\"tables\": [], \"texts\": []}\n",
    "# for box in results['boxes']:\n",
    "#     # Crop table from image\n",
    "#     cropped_img = image.crop((box[0], box[1], box[2], box[3]))\n",
    "#     # TODO: Extract table data from cropped_img and append to data_json[\"tables\"]\n",
    "\n",
    "# # Extract text outside tables\n",
    "# # TODO: Define areas outside tables and use pytesseract to extract text\n",
    "# # Extracted text can be appended to data_json[\"texts\"]\n",
    "\n",
    "# # Save to JSON file\n",
    "# with open('extracted_data.json', 'w') as outfile:\n",
    "#     json.dump(data_json, outfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop PDF images\n",
    "\n",
    "- based on the results generated by the model to extract images that contain tables with a high probability of 0.9.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with adding Padding of 20PXL to the Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%reload_ext autotime\n",
    "\n",
    "def crop_tables(image, page_num):\n",
    "    encoding = feature_extractor(image, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "\n",
    "    width, height = image.size\n",
    "    target_sizes = [(height, width)]\n",
    "    results = feature_extractor.post_process_object_detection(outputs, threshold=0.9, target_sizes=target_sizes)[0]\n",
    "\n",
    "    # Crop tables with scores above 90\n",
    "    high_score_tables = [(score, label, box) for score, label, box in\n",
    "                         zip(results['scores'].tolist(), results['labels'].tolist(), results['boxes'].tolist())\n",
    "                         if score > 0.9]\n",
    "\n",
    "    if high_score_tables:\n",
    "        for idx, (_, _, (xmin, ymin, xmax, ymax)) in enumerate(high_score_tables):\n",
    "            # Increase crop area\n",
    "            xmin -= 20  \n",
    "            ymin -= 20\n",
    "            xmax += 20\n",
    "            ymax += 20\n",
    "            \n",
    "            # Crop the table using PIL with adjusted coordinates\n",
    "            table_img = image.crop((xmin, ymin, xmax, ymax))\n",
    "            # Save the cropped table image\n",
    "            table_img.save(os.path.join(output_folder, f\"{pdf_filename}_page_{page_num}_table_{idx}.png\"), \"PNG\")\n",
    "\n",
    "# Process each page in the PDF\n",
    "for i, image in enumerate(images):\n",
    "    crop_tables(image, i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting Images\n",
    "\n",
    "- Removing images that do not contain tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Folder path\n",
    "folder_path = r\"ExtractTableandCropImages\"\n",
    "# Specific word in the file name\n",
    "specific_word = \"table\"\n",
    "\n",
    "# List all files in the folder\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "# Iterate through the files and delete those that do not have the specific word\n",
    "for file in files:\n",
    "    if specific_word not in file:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        os.remove(file_path)\n",
    "        print(f\"Deleted: {file}\")\n",
    "\n",
    "print(\"Deletion process completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "execution_time_in_minutes = execution_time / 60\n",
    "print(\"Execution time :\", execution_time, \"seconds\")\n",
    "print(\"Execution time:\", execution_time_in_minutes, \"Minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
